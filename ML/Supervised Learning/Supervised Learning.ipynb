{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Series: Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Authored by Adish Jain*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"taxonomy.png\", width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Regression Problem in Two Perspectives:\n",
    "\n",
    "The first is that there exists some natural relationship between some explanatory variables and some response variable. We can never fully know this relationship for certain because of noisy data, but our goal is to uncover the best relationship we can find. Regression can help us discover *correlation*, but not *causation*. \n",
    "\n",
    "The second is that there we will use the predictive power of previous data to train some sort of input-output machine. This machine will be able to take some newly-discovered input and output its best guess of what the response would be to this new data point. \n",
    "\n",
    "The first perspective focuses on the *relationship between our explanatory and response*, while the second focuses more on the *predictive power* of disovering such a relationship. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"linearfit.gif\", width=300px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fit.gif\", width=300px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"polynomialfit.gif\", width=300px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are a variety of Regression problems:  \n",
    "\n",
    "1. Predicting the heights of sons based on heights of their fathers\n",
    "2. How ad expenditures on correlates to video views\n",
    "3. How minutes on court and points scores are related\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Problems for Regression:\n",
    "\n",
    "Remember, regression is just a problem. There are many different ways to frame that problem, and many different tools to solve it. We call these different framings optimization problems. We call these different tools the algorithm or the solver of the optimization problem.\n",
    "\n",
    "Each optimization problem has its own pros & cons, pose their own constraints, have their own solver algorithms and have their own unique solutions. Much like a mechanic who must pick the right tool for the car, a Machine Learner must decide when to use which method & why:\n",
    "\n",
    "1. Least-Squares Linear Regression\n",
    "2. Weighted Least-Squares Linear Regression\n",
    "3. Ridge Regression\n",
    "3. LASSO Regression\n",
    "5. Polynomial Regression\n",
    "6. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are a variety of Classification Problems:\n",
    "\n",
    "The Classification problem is all about identifying the correct label from some finite set of possibilities. For example: \n",
    "1. Identifying hand-written digits (MNIST Dataset)\n",
    "2. Hot Dog or Not Hot Dog (Silicon Valley)\n",
    "3. Spam or Ham\n",
    "4. Cancer or No Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"classification.png\", width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Problems for Classification:\n",
    "\n",
    "Classification is another problem. Much like for Regression problems, there exist a set of algorithms which solve classification problems. Each is simply a tool in your toolbox, to be used at the right place and time:\n",
    "1. Support Vector Machines\n",
    "2. Gaussian Discriminant Analysis (LDA & QDA)\n",
    "3. Decision Trees (& Random Forests)\n",
    "4. Neural Networks\n",
    "6. Nearest Neighbors\n",
    "5. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Word on Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both cases of supervised learning, regression & classification, you can imagine that we have some machine churning out outputs from inputs, and *machine learning* is simply the process during which this machine uses some *training data* to calibrate its knobs and dials, or *parameters/weights*.\n",
    "\n",
    "In a nutshell, most supervised learning problems boil down to framing the problem of learning these weights as some sort of *optimization problem*, using *loss* or *cost* functions as the things we are optimizing over. The *algorithm* you pick will determine the policy in which these knobs and dials are adjusted. Ultimately, it is the value of these weights which matter, and is what we are trying to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"supervised.png\", width=500px>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
