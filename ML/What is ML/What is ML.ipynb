{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Series: What is Machine Learning? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Authored by Adish Jain*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is ML?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term *machine learning* was coined in 1959 by computer scientist Arthur Samuel after his work on creating a checker playing program. Samuel defined machine learning as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \"A field of study that gives computers the ability to learn without being explicitly programmed\" - Arthur Samuel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A Brief History of the Field**\n",
    "\n",
    "*1763:* The Underpinnings of Bayes' Theorem  \n",
    "\n",
    "*1805:* Legendre discovers the method of least-squares  \n",
    "\n",
    "*1913:* Andrey Markov describes techniques known as Markov Chains  \n",
    "\n",
    "*1950:* Turing's Learning Machine  \n",
    "\n",
    "*1951:* First Neural Network machine by Minsky & Edmonds  \n",
    "\n",
    "*1952:* Arthur Samuel (IBM) enables machines to play checkers using Minimax  \n",
    "\n",
    "*1957:* Rosenblatt invents the perceptron \n",
    "\n",
    "*1963:* Michie uses RL to create a machine which can play Tic-Tac-Toe\n",
    "\n",
    "*1967:* The Nearest-Neighbor algorithm was created\n",
    "\n",
    "*1989:* Christopher Watkins develops Q-Learning \n",
    "\n",
    "*1995:* Tin Kam Ho publishes random forests; Cortes & Vapnik publish SVMs\n",
    "\n",
    "*1997:* IBM Deep Blue beats Kasparov\n",
    "\n",
    "*2011:* IBM Watson beats humans in Jeopardy!\n",
    "\n",
    "*2016:* Google's AlphaGo beats humans in Go\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why is ML Important Today**\n",
    "\n",
    "Today, data is the hot commodity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised, Unsupervised, & Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"taxonomy.png\", width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"map.png\", widt=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This ML Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What You Should Know "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probability**\n",
    "1. Conditional Probability\n",
    "2. Bayes' Rule\n",
    "3. Random Variables (Continuous & Discrete)\n",
    "4. Joint & Marginal Distributions\n",
    "5. Expectation & Variance\n",
    "6. Covariance & Correlation\n",
    "7. MLE & MAP\n",
    "8. Multivariate Gaussians\n",
    "\n",
    "**Linear Algebra**\n",
    "1. Vector Spaces\n",
    "2. Eigenvectors\n",
    "3. Trace\n",
    "4. Determinant\n",
    "5. Matrices (Orthogonal, Symmetric, PSDs)\n",
    "6. Quadratic Forms\n",
    "\n",
    "**Calculus**\n",
    "1. Matrix Calculus\n",
    "2. Gradients\n",
    "3. The Jacobian & Hessian\n",
    "4. Optimization\n",
    "5. Convexity\n",
    "\n",
    "****\n",
    "\n",
    "Fantastic Resource: http://gwthomas.github.io/docs/math4ml.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What We'll Cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This series will focus primarily on supervised learning. We will tackle it in five parts:\n",
    "\n",
    "**Part I: The Basics of ML**\n",
    "1. What is ML?\n",
    "2. Supervised Learning\n",
    "3. Unsupervised Learning\n",
    "4. ML in Practice\n",
    "\n",
    "**Part II: Regression**\n",
    "1. Cost/Loss Functions\n",
    "2. Linear Regression\n",
    "3. Flavors of Linear Regression\n",
    "4. Regularization\n",
    "5. Maximum-Likelihood Estimation\n",
    "\n",
    "**Part III: Classification**\n",
    "1. Decision Theory\n",
    "2. Risk Minimization\n",
    "3. Confusion Matrix & ROC Curves\n",
    "4. Logistic Regression\n",
    "5. Support Vector Machines\n",
    "6. Gaussian Discriminant Analysis (LDA & QDA)\n",
    "7. Decision Trees\n",
    "\n",
    "**Part IV: Boosting**\n",
    "1. Random Forests\n",
    "2. AdaBoost\n",
    "\n",
    "**Part V: **\n",
    "1. Bias-Variance Tradeoff\n",
    "2. Subset Selection\n",
    "3. Gradient Descent\n",
    "4. Newton's Method\n",
    "5. Unsupervised Learning Revisited\n",
    "6. ML Abstractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will also have coding and practical use cases in addition to the math & theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
